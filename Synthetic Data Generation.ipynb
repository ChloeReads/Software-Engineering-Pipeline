{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOw81uPDbOrc9dCTEt+35wy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChloeReads/Software-Engineering-Pipeline/blob/main/Synthetic%20Data%20Generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Synthetic Data Generation\n",
        "\n",
        "## Setup Instructions\n",
        "\n",
        "This code assumes you have only loaded Synthetic Data Generation.ipynb into Google colab, if you have already uploaded the below files you can skip the next step and move straight to Installing requirements.txt\n",
        "\n",
        "Run the following code block and upload the following files from the Zip Archive:\n",
        "\n",
        "*   requirements.txt\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CVc6zvHsDUfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "UqjDqHBo6i8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "PB71Hae26qfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing installed libraries\n",
        "import pandas as pd\n",
        "from faker import Faker\n",
        "\n",
        "# As random is built into python it does not need to be installed like previous libraries\n",
        "import random\n",
        "\n",
        "# Setting Faker to us British Names/Locations\n",
        "fake = Faker('en_GB')"
      ],
      "metadata": {
        "id": "AcUUINw8790G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating Lists of Cities and departments as Faker can pull from a huge number and this makes the data closer to the production source\n",
        "\n",
        "locations = ['Edinburgh', 'Glasgow', ' Aberdeen', 'Leeds', 'Manchester', 'London', 'Bristol', 'Cardiff', 'Belfast', 'Birmingham', 'Brighton']\n",
        "departments = ['Human Resources', 'Risk Management','Sales','Marketing','Adminstration','Engineering','Investment','Sciences']"
      ],
      "metadata": {
        "id": "wvOv39qGTl_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating the Staff dataset\n",
        "\n",
        "data = []\n",
        "# Sets the number of Rows, this roughly matches production dataset size\n",
        "for i in range(10000):\n",
        "    new_row = {\n",
        "        'ID': fake.unique.random_int(min=10000, max=99999), # Creates unique ID numbers withing an upper and lower limit\n",
        "        'Full Name': fake.name(), # Creates the Full Name Column, the locale set above determines roughly what kind of names this generates, for this assessment this is fine however in real world scenaries could cause bias issues\n",
        "        'Location': fake.random_element(elements=locations), # Use the predifined list of locations (Major UK Cities)\n",
        "        'Department': fake.random_element(elements=departments) # Use the predefined list of departments\n",
        "    }\n",
        "    data.append(new_row)\n",
        "\n",
        "    # Occasionally duplicate a row 5% of the time (to mimic a real world data quality issue)\n",
        "    if random.random() < 0.05 and len(data) > 0:\n",
        "        row_to_duplicate = random.choice(data)\n",
        "        data.append(row_to_duplicate)\n",
        "\n",
        "\n",
        "df_staff = pd.DataFrame(data)\n",
        "display(df_staff.head())"
      ],
      "metadata": {
        "id": "gGd6_29I-RLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fe05c896"
      },
      "source": [
        "# Extract unique IDs and their departments from the existing DataFrame\n",
        "df_teams_data = df_staff[['ID', 'Department']].drop_duplicates().copy()\n",
        "\n",
        "# Generates a fake Team for each Department.\n",
        "teams_per_department = {}\n",
        "for department in df_teams_data['Department'].unique():\n",
        "    teams_per_department[department] = [f'{department} Team {i+1}' for i in range(random.randint(1, 4))] # 1 to 4 teams per department\n",
        "\n",
        "# Assign a random team from the department's teams to each ID-Department pair\n",
        "df_teams_data['Team'] = df_teams_data['Department'].apply(lambda x: random.choice(teams_per_department[x]))\n",
        "\n",
        "df_teams = df_teams_data\n",
        "display(df_teams.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the IDs from the original DataFrame\n",
        "ids = df_staff['ID'].unique().tolist()\n",
        "\n",
        "# Generate random pay rates for each ID\n",
        "pay_rates_data = []\n",
        "for id in ids:\n",
        "    pay_rates_data.append({\n",
        "        'ID': id,\n",
        "        'Pay Rate': round(fake.random_number(digits=2) + fake.pydecimal(left_digits=2, right_digits=2, positive=True), 2)\n",
        "    })\n",
        "\n",
        "df_pay_rates = pd.DataFrame(pay_rates_data)\n",
        "display(df_pay_rates.head())"
      ],
      "metadata": {
        "id": "cfyia6oUWD7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_staff.to_csv('Staff.csv')\n",
        "df_teams.to_csv('Teams.csv')\n",
        "df_pay_rates.to_csv('PayRates.csv')\n",
        "\n",
        "files.download('Staff.csv')\n",
        "files.download('Teams.csv')\n",
        "files.download('PayRates.csv')"
      ],
      "metadata": {
        "id": "YJQNDZOyWivJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}